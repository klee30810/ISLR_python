{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Regression\n",
    "- Is there a relationship between?\n",
    "- How strong is the relationship?\n",
    "- Which features are associated with the target?\n",
    "- How large the association?\n",
    "- How accurately can we predict target?\n",
    "- Is the relationship linear?\n",
    "- Is there synergy among features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.1 Simple linear regression\n",
    "- predicting a quantitative response Y on the basis of a single predictor X. assumes that there is approximately a linear relationship between X and Y.\n",
    "$$ Y \\approx \\beta_0 + \\beta_1X $$\n",
    "  - $ \\beta_0$ : intercept\n",
    "  - $ \\beta_1$ : slope\n",
    "\n",
    "### 3.1.1 Estimating the coefficients \n",
    "- to obtain coefficient estimates $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ such that the linear model fits the available data well.\n",
    "  - the most common approach involves minimizing the least squares criterion\n",
    "    $e_i = y_i - \\hat{y}_i$ : residual\n",
    "    $$ RSS = e^2_1 + e^2_2 + ... + e^2_n = (y_1-\\hat{\\beta}_0-\\hat{\\beta}_1x_1)^2 + (y_2-\\hat{\\beta}_0-\\hat{\\beta}_1x_2)^2 + ... + (y_n-\\hat{\\beta}_0-\\hat{\\beta}_1x_n)^2 \\\\ \\hat{\\beta_1} = \\frac{\\sum^n_{i=1}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum^n_{i=1}(x_i-\\bar{x})^2} \\\\ \\hat{\\beta_0}=\\bar{y}-\\hat{\\beta_1}\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Assessing the accuracy of the coefficient estimates\n",
    "$$ Y = \\beta_0 + \\beta_1X+\\epsilon $$\n",
    "- $\\epsilon$ : catch-all for what we miss with this simple model\n",
    "- The sample mean and the population mean are different, but in general hte smaple mean will provide a good estimate of the population mean.\n",
    "- If we use the sample mean $\\hat{\\mu}$ to estimate $\\mu$, this istemate is *unbiased*, in the sense that on average, we expect $\\hat{\\mu}$ to equal $\\mu$\n",
    "  - On the basis of one particular set of observations, $\\hat{\\mu}$ might overestimate of underestimate $\\mu$, then this average would exactly equal $\\mu$\n",
    "- How accurate is the sample mean $\\hat{\\mu}$ as an estimate of $\\mu$?\n",
    "  - standard error of $\\hat\\mu$ $$Var{\\hat\\mu}=SE(\\hat\\mu)^2=\\frac{\\sigma^2}{n} $$\n",
    "    - the average amount that his estimate $\\hat\\mu$ differs from the actual $\\mu$\n",
    "  $$ SE(\\hat\\beta_0)^2 = \\sigma^2[\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum^n_{i=1}(x_i-\\bar{x})^2}], SE(\\hat\\beta_1)^2 = \\frac{\\sigma^2}{\\sum^n_{i=1}(x_i-\\bar{x})^2} $$\n",
    "    - SE is smaller when $x_i$ are more spread out; intuitiely we have more leverage to estimate a slope.\n",
    "  - In general, $\\sigma^2$ is not konwn, bur can be estimated from the data $RSE = \\sqrt{RSS/(n-2)}\n",
    "- Standard erros can be used to compute *confidence intervals*\n",
    "  - 95% confidence interval : a range of values such that with 95% probability, the range will contain the true unknown value of the parameter\n",
    "    - If we take repeated samples and construct the confidnece interval for each sample, 95% of the invercals will contain the true unknown value of the parameter\n",
    "    - $\\hat\\beta_1 \\pm 2 \\dot SE(\\hat\\beta_1)$\n",
    "- Standard errors can also be used to perform hypothesis tests on the coefficients\n",
    "  - $H_0$ : There is no relationship between X and Y, $\\beta_1=0$\n",
    "  - $H_1$ : There is some relationship between X and Y, $\\beta_0\\neq 0$\n",
    "  - need to determine whether $\\hat\\beta_1$ is sufficiently far from zero that we can confident that $\\beta$ is non-zero.\n",
    "    - depends on the accuracy of $\\hat\\beta_1$ which depends on SE($\\hat\\beta_1$) : if $\\hat\\beta_1$ is small, then even relatively small values of $\\hat\\beta_1$ may probide strong evidence that $\\beta_1 \\neq 0$. If SE($\\hat\\beta_1$) is large, $\\hat\\beta_1$ must be large in absolute value to reject the null hypothesis\n",
    "    - use *t-statistic* : $t = \\frac{\\hat\\beta_1-0}{SE(\\hat\\beta_1)} $=> measures standard deviation that \\hat\\beta_1 is away from 0.\n",
    "      - if there is no relationship, a t-distribution with n-2 degrees of freedom\n",
    "    - t-distribution has a bell shape and for values greather than 30 is similar to the stadard normal distribution.\n",
    "    - a small p-value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to cahnce, in the absence of any real association between the predictor and the response => there is an association between the predictor and teh response. => **reject null hypothesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Assessing the accuracy of the model\n",
    "- Want to quantify the extent to which the model fits the data => residual standard error (RSE) & $R^2$\n",
    "- Residual Standard Error : estimate of the standard deviation of $\\epsilon$\n",
    "  - actual target deviates from the regression line by RSE units, on average\n",
    "  - even if the model were correct and the coefficients were known exactly, prediction would still be off by RSE units on average.\n",
    "  - a measure of the lack of fit of the model to the data.\n",
    "- $R^2$ statistic : proportion of variance explained\n",
    "  - a value between 0 and 1 & independent of the scale of Y\n",
    "    $$ R^2 = \\frac{TSS-RSS}{TSS} = 1-\\frac{RSS}{TSS} \\\\ TSS = \\sum(y_i - \\bar{y})^2,\\ total\\ sum\\ of\\ squares$$\n",
    "  - TSS : amount of variability ingerent in the response before the regression is performed\n",
    "  - RSS : amount of variability that is left unexplained after performing regression.\n",
    "- correlation : measure of the linear relationship between X and Y\n",
    "  $$ Cor(X,Y) = \\frac{\\sum^n_{i=1}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum^n_{i=1}(x_i-\\bar{x})^2}\\sqrt{\\sum^n_{i=1}(y_i-\\bar{y})^2}}\n",
    "  - correlation quantifies the association between a single pair of variables rather than between a larger number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Multiple linear regression\n",
    "- need to assess the relationship to the response with multiple predictors\n",
    "- separate simple linear regressions \n",
    "  - unclear how to make a single prediction of target given the three predictors since each is associated with a separate regression.\n",
    "  - each regression ignores other predictors for estimating coefficients.\n",
    "- extend the simple linear regression so that it can accomodate multiple predictors by giving each predictor a separate slope coefficient in a single model.\n",
    "  $$ Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p+\\epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Estimating the regression coefficients\n",
    "- parameters are estimated with the same least squares approach to minimize the sum of squared residuals\n",
    "  $$ RSS = \\sum^n_{i=1}(y_i-\\hat{y_i})^2 = \\sum^n_{i=1}(y_i-\\hat\\beta_0-\\hat\\beta_1x_{i1}-\\hat\\beta_2x_{i2}-...-\\hat\\beta_px_{ip})^2\n",
    "- simple regression coefficient : represent relationship ignoring other predictors\n",
    "- multiple regression coefficient : represent relationship holding other predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2.2 Some important questions\n",
    "1. Is at least one of the predictors X1,X2, . . . ,Xp useful in predicting the response?\n",
    "2. Do all the predictors help to explain Y , or is only a subset of the predictors useful?\n",
    "3. How well does the model fit the data?\n",
    "4. Given a set of predictor values, what response value should we predict,and how accurate is our prediction?\n",
    "\n",
    "\n",
    "1) Is there a relationship between the response and predictors?\n",
    "- $$ H_0 : \\beta_1 = \\beta_2=...=\\beta_p=0 \\\\ H_1 : at\\ least\\ onw\\ \\beta_j\\ is\\ nonzero $$\n",
    "- computing F-statistic $ F=\\frac{(TSS-RSS)/p}{RSS/(n-p-1)} $\n",
    "  - linear model assumption correct : $E[RSS/(n-p-1)]=\\sigma^2$\n",
    "  - provided $H_0$ true : $E[(TSS-RSS)/p]=\\sigma^2 $ -> when there is no relationship between the response and predictors, F-statistic values close to 1(분자 분모 모두 분산). / If $H_a$ is true, then $E[(TSS-RSS)/p] > \\sigma^2$, F-statistic values larger than 1(분자가 시그마보다 커짐).\n",
    "- When n is large, an F-statistic just a little larger than 1 still provide evidence against $H_0$. / a larger F-statistic is needed to reject $H_0$ if n is small.\n",
    "- When $H_0$ is true and the errors $\\epsilon_i$ have a normal distribution, F-statistic follows an F-distribution. Compute the p-value associated with the F-statistic.\n",
    "- WHY DO WE NEED TO LOOK AT THE OVERALL F-STATISTIC when looking p-vals? If any one of p-values for the individual variables is very small, then *at least one of the predictors is related to the response*, but this is flawed, especially when the number of predictors p is large.\n",
    "  - If p=100 & $H_0$ is true, about 5% of p-values associated with each variable will be below 0.05 by chance. => **we expect to see approximately 5 small p-values even in the absence of any true association**\n",
    "  - F-statistic does not suffer from this : adjusts for the number of predictors\n",
    "- If p > n, we cannot fit the multiple linear regression model using least squares, so F-statistic cannot be used.\n",
    "\n",
    "2) Deciding on important variables\n",
    "- looking only individual p-values makes false discoveries.\n",
    "- variable selection : determine which predictors are associated with the response. -> $2^p$ models are needed. efficient approach to choose a smaller set of models to consider.\n",
    "  - forward selection : begin with null model, then fit p simple linear regressions and add to the null model the variable that results in the lowest RSS\n",
    "  - backward selection : begin with all variables, then remove the variable with the largest p-value. New (p-1) variable model is fit.\n",
    "  - mixed selection : begin with no variables, add the variable that provides the best fit. If at any point the p-value for one of the variables in the model rises above a certain threshold, then remove that varaible from the mdoel.\n",
    "\n",
    "3) Model fit\n",
    "- $R^2$ increases with added predictors despite no real improvement -> likely lead to poor results on independent test samples due to overfitting\n",
    "- non-linear pattern suggests a synergy or interaction effect between the predictors.\n",
    "\n",
    "4) Predictions\n",
    "- $ f(X) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p $\n",
    "- Due to irreducible error, we cannot perfectly predict. Prediction intervals are always wider than confidence intervals since they incorporate both the error in the estimate and the uncertainty as to how much individual point will differ from the popultion plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Other Considerations in the regression model\n",
    "### 3.3.1 Qualitative predictors\n",
    "- predictors with only two levels : 1,0 \n",
    "- predictors with more than two levels : create additional dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Extenstions of the linear model\n",
    "- linear model assumption : **relationship between the predictors and response are additive and linear**\n",
    "  - additivity : the association with predictor and response does not dpend on other predictors\n",
    "  - linearlity : the change in the response associated with a one-unit change in predictor is constant, regardless of the value of X\n",
    "- removing additive assumption\n",
    "  - add interaction term by computing product of $X_1$ & $X_2$\n",
    "  $$ Y = \\beta_0 + (\\beta_1 + \\beta_3X_2)X_1 + \\beta_2X_2 + \\epsilon \\\\ = \\beta_0 + \\bar{\\beta_1}X_1+\\beta_2X_2+\\epsilon\n",
    "  - \\bar{\\beta_1}$$ is now a function of $X_2$, the association between $X_1$ and $Y$ is no longer constant\n",
    "  - **Hierarchical principle : if we include an interaction in a model, we should also include the main effects, even if the p-values associated with their coefficients are not significant.**\n",
    "- Non-linear Relationships\n",
    "  - polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Potential problems\n",
    "1. Non-linearity of the data\n",
    "   - If the true relationship is far from lienar, then virtually all of the conclusions that we draw from the fit are suspect\n",
    "   - Residual plots (residuals vs predicted values): Ideally the residual plot will show no discernible pattern.\n",
    "2. Correlation of error terms.\n",
    "   - the error terms are uncorrelated : standard errors are based on the assumption of uncorrelated error terms.\n",
    "   - such correlation freqeuntly occur in time-series data\n",
    "     - obtained at adjacent time points will have positively correlated errors\n",
    "     - plot residuals\n",
    "3. Non-constant variance of error terms.\n",
    "- the error terms have a constant variance $Var(\\epsilon_i)=\\sigma^2$ -> confidence intervals and hypothesis tests rely upon this assumption.\n",
    "- residual plot -> use concave function transformation log Y or $\\sqrt{Y}$\n",
    "4. Outliers.\n",
    "- remove them if they have little effect on the least squares line\n",
    "- studentized residuals : computed by dividing each residual $\\epsilon_i$ by its estimated stadrd error (-2 ~ 2) \n",
    "5. High-leverage points.\n",
    "- leverage statistic : $h_i=\\frac{1}{n}+\\frac{(x_i-\\bar{x})^2}{\\sum^n_{i'=1}(x_{i'}-\\bar{x})^2}$\n",
    "\n",
    "6. Collinearity.\n",
    "- two or more predictor variables are closely related to one another\n",
    "- collinearity reduces the accuracy of the estimated coefficients, their standard error to grow\n",
    "  - t-statistic is calculated by dividing coefficient by its standard error -> collinearity results in a decline in the t-statistic -> may fail to reject $H_0$\n",
    "- VIF(variance inflation factor) : the ratio of the variance of coefficient when fitting the full model divided by the variance of coefficient if fit on its on. larger than 5 or 10 indicates collinearity\n",
    "  $$VIF(\\hat{\\beta_j}=\\frac{1}{1-R^2_{X_j|X_{-j}}}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.6 Lab : Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   lstat  medv  \n",
       "1   4.98  24.0  \n",
       "2   9.14  21.6  \n",
       "3   4.03  34.7  \n",
       "4   2.94  33.4  \n",
       "5   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv(\"../data/boston.csv\", index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.544\n",
      "Model:                            OLS   Adj. R-squared:                  0.543\n",
      "Method:                 Least Squares   F-statistic:                     601.6\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):           5.08e-88\n",
      "Time:                        14:34:12   Log-Likelihood:                -1641.5\n",
      "No. Observations:                 506   AIC:                             3287.\n",
      "Df Residuals:                     504   BIC:                             3295.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     34.5538      0.563     61.415      0.000      33.448      35.659\n",
      "lstat         -0.9500      0.039    -24.528      0.000      -1.026      -0.874\n",
      "==============================================================================\n",
      "Omnibus:                      137.043   Durbin-Watson:                   0.892\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              291.373\n",
      "Skew:                           1.453   Prob(JB):                     5.36e-64\n",
      "Kurtosis:                       5.319   Cond. No.                         29.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "x = df['lstat']\n",
    "y = df['medv']\n",
    "\n",
    "model = sm.OLS.from_formula('medv ~ lstat', data=df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.551\n",
      "Model:                            OLS   Adj. R-squared:                  0.549\n",
      "Method:                 Least Squares   F-statistic:                     309.0\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):           2.98e-88\n",
      "Time:                        14:11:14   Log-Likelihood:                -1637.5\n",
      "No. Observations:                 506   AIC:                             3281.\n",
      "Df Residuals:                     503   BIC:                             3294.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     33.2228      0.731     45.458      0.000      31.787      34.659\n",
      "lstat         -1.0321      0.048    -21.416      0.000      -1.127      -0.937\n",
      "age            0.0345      0.012      2.826      0.005       0.011       0.059\n",
      "==============================================================================\n",
      "Omnibus:                      124.288   Durbin-Watson:                   0.945\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              244.026\n",
      "Skew:                           1.362   Prob(JB):                     1.02e-53\n",
      "Kurtosis:                       5.038   Cond. No.                         201.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "### 3.6.3 Multiple linear regression\n",
    "reg = sm.OLS.from_formula(\"medv ~ lstat + age\", data=df)\n",
    "result = reg.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age',\n",
       " 'chas',\n",
       " 'crim',\n",
       " 'dis',\n",
       " 'indus',\n",
       " 'lstat',\n",
       " 'medv',\n",
       " 'nox',\n",
       " 'ptratio',\n",
       " 'rad',\n",
       " 'rm',\n",
       " 'tax',\n",
       " 'zn'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.734\n",
      "Model:                            OLS   Adj. R-squared:                  0.728\n",
      "Method:                 Least Squares   F-statistic:                     113.5\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):          2.23e-133\n",
      "Time:                        14:35:24   Log-Likelihood:                -1504.9\n",
      "No. Observations:                 506   AIC:                             3036.\n",
      "Df Residuals:                     493   BIC:                             3091.\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     41.6173      4.936      8.431      0.000      31.919      51.316\n",
      "crim          -0.1214      0.033     -3.678      0.000      -0.186      -0.057\n",
      "zn             0.0470      0.014      3.384      0.001       0.020       0.074\n",
      "indus          0.0135      0.062      0.217      0.829      -0.109       0.136\n",
      "chas           2.8400      0.870      3.264      0.001       1.131       4.549\n",
      "nox          -18.7580      3.851     -4.870      0.000     -26.325     -11.191\n",
      "rm             3.6581      0.420      8.705      0.000       2.832       4.484\n",
      "age            0.0036      0.013      0.271      0.787      -0.023       0.030\n",
      "dis           -1.4908      0.202     -7.394      0.000      -1.887      -1.095\n",
      "rad            0.2894      0.067      4.325      0.000       0.158       0.421\n",
      "tax           -0.0127      0.004     -3.337      0.001      -0.020      -0.005\n",
      "ptratio       -0.9375      0.132     -7.091      0.000      -1.197      -0.678\n",
      "lstat         -0.5520      0.051    -10.897      0.000      -0.652      -0.452\n",
      "==============================================================================\n",
      "Omnibus:                      171.096   Durbin-Watson:                   1.077\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              709.937\n",
      "Skew:                           1.477   Prob(JB):                    6.90e-155\n",
      "Kurtosis:                       7.995   Cond. No.                     1.17e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.17e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reg = sm.OLS.from_formula('medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+lstat', data=df)\n",
    "result = reg.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crim</td>\n",
       "      <td>1.767486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zn</td>\n",
       "      <td>2.298459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indus</td>\n",
       "      <td>3.987181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chas</td>\n",
       "      <td>1.071168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nox</td>\n",
       "      <td>4.369093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rm</td>\n",
       "      <td>1.912532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>3.088232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dis</td>\n",
       "      <td>3.954037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rad</td>\n",
       "      <td>7.445301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tax</td>\n",
       "      <td>9.002158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ptratio</td>\n",
       "      <td>1.797060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lstat</td>\n",
       "      <td>2.870777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column       VIF\n",
       "0      crim  1.767486\n",
       "1        zn  2.298459\n",
       "2     indus  3.987181\n",
       "3      chas  1.071168\n",
       "4       nox  4.369093\n",
       "5        rm  1.912532\n",
       "6       age  3.088232\n",
       "7       dis  3.954037\n",
       "8       rad  7.445301\n",
       "9       tax  9.002158\n",
       "10  ptratio  1.797060\n",
       "11    lstat  2.870777"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "pd.DataFrame({'column': column, 'VIF':variance_inflation_factor(reg.exog, i)}\n",
    "    for i, column in enumerate(reg.exog_names) if column != \"Intercept\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.556\n",
      "Model:                            OLS   Adj. R-squared:                  0.553\n",
      "Method:                 Least Squares   F-statistic:                     209.3\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):           4.86e-88\n",
      "Time:                        14:43:34   Log-Likelihood:                -1635.0\n",
      "No. Observations:                 506   AIC:                             3278.\n",
      "Df Residuals:                     502   BIC:                             3295.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     36.0885      1.470     24.553      0.000      33.201      38.976\n",
      "lstat         -1.3921      0.167     -8.313      0.000      -1.721      -1.063\n",
      "age           -0.0007      0.020     -0.036      0.971      -0.040       0.038\n",
      "lstat:age      0.0042      0.002      2.244      0.025       0.001       0.008\n",
      "==============================================================================\n",
      "Omnibus:                      135.601   Durbin-Watson:                   0.965\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              296.955\n",
      "Skew:                           1.417   Prob(JB):                     3.29e-65\n",
      "Kurtosis:                       5.461   Cond. No.                     6.88e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.88e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "### 3.6.4 Interaction Terms\n",
    "print(sm.OLS.from_formula('medv ~ lstat * age', data=df).fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.641\n",
      "Model:                            OLS   Adj. R-squared:                  0.639\n",
      "Method:                 Least Squares   F-statistic:                     448.5\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):          1.56e-112\n",
      "Time:                        14:56:13   Log-Likelihood:                -1581.3\n",
      "No. Observations:                 506   AIC:                             3169.\n",
      "Df Residuals:                     503   BIC:                             3181.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           42.8620      0.872     49.149      0.000      41.149      44.575\n",
      "lstat               -2.3328      0.124    -18.843      0.000      -2.576      -2.090\n",
      "I(lstat * lstat)     0.0435      0.004     11.628      0.000       0.036       0.051\n",
      "==============================================================================\n",
      "Omnibus:                      107.006   Durbin-Watson:                   0.921\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              228.388\n",
      "Skew:                           1.128   Prob(JB):                     2.55e-50\n",
      "Kurtosis:                       5.397   Cond. No.                     1.13e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.13e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(sm.OLS.from_formula('medv ~ lstat + I(lstat*lstat)', data=df).fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   df_resid           ssr  df_diff     ss_diff           F        Pr(>F)\n",
      "0     504.0  19472.381418      0.0         NaN         NaN           NaN\n",
      "1     503.0  15347.243158      1.0  4125.13826  135.199822  7.630116e-28\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.stats.anova as anova\n",
    "\n",
    "model1 = sm.OLS.from_formula('medv ~ lstat', data=df).fit()\n",
    "model2 = sm.OLS.from_formula('medv ~ lstat + I(lstat*lstat)', data=df).fit()\n",
    "\n",
    "print(sm.stats.anova_lm(model1, model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis test comparing the two models\n",
    "- H0 : two models fit the data equally well\n",
    "- H1 : the full model is superior => F-stat 135 & p-val is virtually zero -> H0 is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.665\n",
      "Model:                            OLS   Adj. R-squared:                  0.664\n",
      "Method:                 Least Squares   F-statistic:                     1000.\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):          9.28e-122\n",
      "Time:                        15:09:09   Log-Likelihood:                -1563.6\n",
      "No. Observations:                 506   AIC:                             3131.\n",
      "Df Residuals:                     504   BIC:                             3140.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        52.1248      0.965     54.004      0.000      50.228      54.021\n",
      "np.log(lstat)   -12.4810      0.395    -31.627      0.000     -13.256     -11.706\n",
      "==============================================================================\n",
      "Omnibus:                      126.181   Durbin-Watson:                   0.918\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              323.855\n",
      "Skew:                           1.237   Prob(JB):                     4.74e-71\n",
      "Kurtosis:                       6.039   Cond. No.                         11.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model3 = sm.OLS.from_formula('medv ~ np.log(lstat)', data=df).fit()\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseat_df = pd.read_csv('../data/Carseats.csv')\n",
    "carseat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.873\n",
      "Model:                            OLS   Adj. R-squared:                  0.870\n",
      "Method:                 Least Squares   F-statistic:                     243.4\n",
      "Date:                Sun, 11 Dec 2022   Prob (F-statistic):          1.60e-166\n",
      "Time:                        15:29:19   Log-Likelihood:                -568.99\n",
      "No. Observations:                 400   AIC:                             1162.\n",
      "Df Residuals:                     388   BIC:                             1210.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               5.6606      0.603      9.380      0.000       4.474       6.847\n",
      "Urban[T.Yes]            0.1229      0.113      1.088      0.277      -0.099       0.345\n",
      "US[T.Yes]              -0.1841      0.150     -1.229      0.220      -0.479       0.111\n",
      "ShelveLoc[T.Good]       4.8502      0.153     31.678      0.000       4.549       5.151\n",
      "ShelveLoc[T.Medium]     1.9567      0.126     15.516      0.000       1.709       2.205\n",
      "CompPrice               0.0928      0.004     22.378      0.000       0.085       0.101\n",
      "Price                  -0.0954      0.003    -35.700      0.000      -0.101      -0.090\n",
      "Population              0.0002      0.000      0.561      0.575      -0.001       0.001\n",
      "Advertising             0.1231      0.011     11.066      0.000       0.101       0.145\n",
      "Age                    -0.0460      0.003    -14.472      0.000      -0.052      -0.040\n",
      "Education              -0.0211      0.020     -1.070      0.285      -0.060       0.018\n",
      "Income                  0.0158      0.002      8.565      0.000       0.012       0.019\n",
      "==============================================================================\n",
      "Omnibus:                        0.811   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.667   Jarque-Bera (JB):                0.765\n",
      "Skew:                           0.107   Prob(JB):                        0.682\n",
      "Kurtosis:                       2.994   Cond. No.                     4.15e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.15e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "predictors = set(carseat_df.columns) - set(['Sales'])\n",
    "features = [col +' + ' for col in predictors]\n",
    "features_str = ''.join(features)[:-2]\n",
    "\n",
    "carseats_model = sm.OLS.from_formula('Sales ~ ' + features_str, data=carseat_df).fit()\n",
    "print(carseats_model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kmlee')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d50b53f7eecc192699096c3b322d2e418f52a0f23d06ad75ff9fc286d66daf3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
