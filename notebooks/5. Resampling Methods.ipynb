{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Resampling Methods\n",
    "- 훈련 데이터셋부터 반복적으로 샘플링\n",
    "- 적합된 모델의 추가적인 데이터를 얻기 위하여 관심이 있는 각 샘플의 모델을 다시 적합\n",
    "- 지속적으로 다른 훈련데이터의 다른 부분집합을 사용하는 같은 통계적 방법을 여러번 사용하며 적합화하기 때문에 많은 계산을 필요로하나, 최근의 기술적 발전으로 인해서 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Cross-Validation\n",
    "- test error : 모델 트레이닝에 사용되지 않은 데이터셋에서의 오류\n",
    "### 5.1.1 The Validation Set Approach\n",
    "- 가능한 데이터셋을 훈련 데이터셋과 테스트 데이터셋으로 나누는 것\n",
    "- 단점\n",
    "  - 훈련 데이터셋과 테스트 데이터셋에 어떤 데이터가 속해 있는지에 따라 결과가 크게 차이날 수 있다\n",
    "  - 통계적 방법론들이 적은 수의 데이터로 훈련받으면 성능이 좋지 않으므로, 검증 오류가 테스트 오류를 과대하게 할 수 있다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Leave-One-Out Cross-Validation\n",
    "- 데이터셋을 둘로 나누나, 관측치 하나만 검증용, 나머지는 훈련용 데이터로 사용\n",
    "  - $(x_1, y_1)$는 적합과정에 사용되지 않았으므로 $ MSE_1 = (y_1-\\hat{y_1})^2 $는 unbiased결과를 보여주나, 하나의 관측치에 대한 결과이므로 변동성이 크다\n",
    "- 이 과정을 n-1 번의 나머지 데이터에 대해서 지속 반복해준 후, 평균화  $$ CV_{(n)}=\\frac{1}{n}\\sum^n_{i=1}MSE_i $$\n",
    "  - 매우 작은 bias : 전체 데이터셋에 대해 n-1번 반복하므로, 훈련 데이터셋이 큰 효과 \n",
    "  - 여러번 반복해도 훈련/검증 데이터셋에 대한 무작위성이 없음   \n",
    "  - 모델이 n 번 적합되어야 하므로 시간과 계산이 많이 필요함\n",
    "    - 최소 제곱법 진행 시, 하나의 모델과 비용이 같게 하는 공식 $$ CV_{(n)}=\\frac{1}{n}\\sum^n_{i=1}(frac{y_i-\\hat{y}_1}{1-h_i})^2 \\\\ h_i(leverage)=\\frac{1}{n}+\\frac{(x_i-\\bar{x})^2}{\\sum^n_{i'=1}(x_{i'}-\\bar{x})^2} $$\n",
    "    - i번째 잔차가 1-h로 나누어진다는 것을 제외하고는 단순 MSE와 비슷.\n",
    "    - leverage는 1/n ~ 1사이의 값을 가지며, 해당 모델의 적합에 해당 관측치의 영향력을 반영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 k-Fold Cross-Validation\n",
    "- 임의로 데이터셋을 거의 같은 사이즈의 k개의 그룹으로 나눔\n",
    "  - 첫 그룹은 검증용을 사용하고, 나머지 그룹으로 적합\n",
    "  - 위 과정을 그룹 수 만큼 반복하고 평균한 값이 추정치 $$ CV_{k}=\\frac{1}{k}\\sum^k_{i=1}MSE_i $$\n",
    "- k를 보통 5,10으로 가져가서 계산비용의 이득을 봄. 각 그룹의 데이터 변동성의 영향을 받으나 전체적인 오차의 양은 비교적 일정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 Bias-Variance Trade-Off for k-Fold Cross-Validation\n",
    "- k-Fold가 Bias-Variance 관계로 인하여 LOOCV보다 나은 결과를 줄 수 있다\n",
    "  - 훈련데이터셋 크기의 차이로 bias 최소화 관점에서는 LOOCV가 k-fol보다 나음\n",
    "  - LOOCV는 많은 적합 모델들의 평균이며, 각 모델들은 거의 비슷한 관측치로부터 학습이 되므로 결과물들은 서로 크게 상관관계를 갖고 있다. k-fold의 경우, 각 그룹의 훈련 데이터셋이 상관관계가 덜하므로 variance가 크다\n",
    "  - 실험적으로 k-fold 5, 10그룹 정도가 매우 높은 variance나 bias로 인한 문제를 덜 겪는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1.5 Cross-vAlidation on Classification Problems\n",
    "- regression에서는 MSE를 사용하는 대신 오분류된 관측치 갯수를 오류 체크에 사용함 $$ CV_{(n)}=\\frac{1}{n}\\sum^n_{i=1}Err_i,\\quad Err_i=I(y_i\\neq \\hat{y_i}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 The Bootstrap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kmlee')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d50b53f7eecc192699096c3b322d2e418f52a0f23d06ad75ff9fc286d66daf3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
