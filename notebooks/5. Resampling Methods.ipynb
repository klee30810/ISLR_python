{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Resampling Methods\n",
    "- 훈련 데이터셋부터 반복적으로 샘플링\n",
    "- 적합된 모델의 추가적인 데이터를 얻기 위하여 관심이 있는 각 샘플의 모델을 다시 적합\n",
    "- 지속적으로 다른 훈련데이터의 다른 부분집합을 사용하는 같은 통계적 방법을 여러번 사용하며 적합화하기 때문에 많은 계산을 필요로하나, 최근의 기술적 발전으로 인해서 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Cross-Validation\n",
    "- test error : 모델 트레이닝에 사용되지 않은 데이터셋에서의 오류\n",
    "### 5.1.1 The Validation Set Approach\n",
    "- 가능한 데이터셋을 훈련 데이터셋과 테스트 데이터셋으로 나누는 것\n",
    "- 단점\n",
    "  - 훈련 데이터셋과 테스트 데이터셋에 어떤 데이터가 속해 있는지에 따라 결과가 크게 차이날 수 있다\n",
    "  - 통계적 방법론들이 적은 수의 데이터로 훈련받으면 성능이 좋지 않으므로, 검증 오류가 테스트 오류를 과대하게 할 수 있다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Leave-One-Out Cross-Validation\n",
    "- 데이터셋을 둘로 나누나, 관측치 하나만 검증용, 나머지는 훈련용 데이터로 사용\n",
    "  - $(x_1, y_1)$는 적합과정에 사용되지 않았으므로 $ MSE_1 = (y_1-\\hat{y_1})^2 $는 unbiased결과를 보여주나, 하나의 관측치에 대한 결과이므로 변동성이 크다\n",
    "- 이 과정을 n-1 번의 나머지 데이터에 대해서 지속 반복해준 후, 평균화  $$ CV_{(n)}=\\frac{1}{n}\\sum^n_{i=1}MSE_i $$\n",
    "  - 매우 작은 bias : 전체 데이터셋에 대해 n-1번 반복하므로, 훈련 데이터셋이 큰 효과 \n",
    "  - 여러번 반복해도 훈련/검증 데이터셋에 대한 무작위성이 없음   \n",
    "  - 모델이 n 번 적합되어야 하므로 시간과 계산이 많이 필요함\n",
    "    - 최소 제곱법 진행 시, 하나의 모델과 비용이 같게 하는 공식 $$ CV_{(n)}=\\frac{1}{n}\\sum^n_{i=1}(frac{y_i-\\hat{y}_1}{1-h_i})^2 \\\\ h_i(leverage)=\\frac{1}{n}+\\frac{(x_i-\\bar{x})^2}{\\sum^n_{i'=1}(x_{i'}-\\bar{x})^2} $$\n",
    "    - i번째 잔차가 1-h로 나누어진다는 것을 제외하고는 단순 MSE와 비슷.\n",
    "    - leverage는 1/n ~ 1사이의 값을 가지며, 해당 모델의 적합에 해당 관측치의 영향력을 반영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 k-Fold Cross-Validation\n",
    "- 임의로 데이터셋을 거의 같은 사이즈의 k개의 그룹으로 나눔\n",
    "  - 첫 그룹은 검증용을 사용하고, 나머지 그룹으로 적합\n",
    "  - 위 과정을 그룹 수 만큼 반복하고 평균한 값이 추정치 $$ CV_{k}=\\frac{1}{k}\\sum^k_{i=1}MSE_i $$\n",
    "- k를 보통 5,10으로 가져가서 계산비용의 이득을 봄. 각 그룹의 데이터 변동성의 영향을 받으나 전체적인 오차의 양은 비교적 일정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 Bias-Variance Trade-Off for k-Fold Cross-Validation\n",
    "- k-Fold가 Bias-Variance 관계로 인하여 LOOCV보다 나은 결과를 줄 수 있다\n",
    "  - 훈련데이터셋 크기의 차이로 bias 최소화 관점에서는 LOOCV가 k-fol보다 나음\n",
    "  - LOOCV는 많은 적합 모델들의 평균이며, 각 모델들은 거의 비슷한 관측치로부터 학습이 되므로 결과물들은 서로 크게 상관관계를 갖고 있다. k-fold의 경우, 각 그룹의 훈련 데이터셋이 상관관계가 덜하므로 variance가 크다\n",
    "  - 실험적으로 k-fold 5, 10그룹 정도가 매우 높은 variance나 bias로 인한 문제를 덜 겪는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1.5 Cross-vAlidation on Classification Problems\n",
    "- regression에서는 MSE를 사용하는 대신 오분류된 관측치 갯수를 오류 체크에 사용함 $$ CV_{(n)}=\\frac{1}{n}\\sum^n_{i=1}Err_i,\\quad Err_i=I(y_i\\neq \\hat{y_i}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 The Bootstrap\n",
    "- 해당 통계 모델의 불확실성을 정량화 가능.\n",
    "- 모델의 회귀계수의 변동성 평가를 bootstrap을 사용해보자\n",
    "- 두 금융자산에 투자하고 X, Y가 결과물일 경우, $\\alpha$ 만큼 X, $1-\\alpha$만큼 Y에 투자 가정. 결과값의 분산이 최소화되는 $\\alpha$를 찾아보자 : $Var(\\alpha X + (1-\\alpha)Y)$의 최소화\n",
    "  $$ \\alpha = \\frac{\\sigma^2_Y-\\sigma_{XY}}{\\sigma^2_X+\\sigma^2_Y-2\\sigma_{XY}}\\\\\\sigma^2_X=Var(X),\\sigma^2_Y=Var(Y),\\sigma_{XY}=Cov(X,Y) $$\n",
    "  - 실제로는 $\\sigma^2_X, \\sigma^2_Y, \\sigma_{XY}$를 알 수 없으므로 추정치를 사용함 $$ \\hat{\\alpha} = \\frac{\\hat{\\sigma}^2_Y-\\hat{\\sigma}_{XY}}{\\hat{\\sigma}^2_X+\\hat{\\sigma}^2_Y-2\\hat{\\sigma}_{XY}} $$\n",
    "  - 1000번 시뮬레이션을 통해서$\\sigma^2_X=1,\\ \\sigma^2_Y=1.25,\\ \\sigma^2_{XY}=0.5 $로 정하고 $\\alpha=0.6$을 얻음.\n",
    "  - 1000번의 평균을 취하면 $$\\bar{\\alpha}=\\frac{1}{1000}\\sum^{1000}_{r=1}\\hat{\\alpha_r}=0.5996 \\\\ \\sqrt{\\frac{1}{1000-1}\\sum^{1000}_{r=1}(\\hat{\\alpha}_r-\\bar{\\alpha})^2}=0.083 $$\n",
    "  - 모집단에서 평균 임의 추출시 $\\hat\\alpha$는 실제 값에서 평균적으로 0.08만큼 다를 수 있음을 의미\n",
    "- 실제로는 진짜 모집단의 새 샘플을 만들 수 없으므로 적용할 수 없음. bootstrap을 통해서새로운 샘플 데이터를 얻는 과정을 진행하여, 추가적인 샘플을 만들지 않고도 $\\hat{\\alpha}$의 변동성을 얻을 수 있다\n",
    "- 모집단으로부터 반복적으로 독립적인 데이터셋을 얻는 것 대신, 기존 데이터셋으로 부터 반복적으로 샘플링 함으로써 다른 데이터셋을 얻을 수 있다\n",
    "  - 해당 샘플링은 **with replacement**를 통해서 진행된다. 같은 관측치가 한번 이상 더 관측될 수 있음. 해당 과정을 B번 반복하여 B개의 다른 bootstrap 샘플 셋 생성하고 표준편차를 구할 수 있다. $$ SE_B(\\hat\\alpha)=\\sqrt{\\frac{1}{(B-1)}\\sum^N_{r=1}(\\hat{\\alpha}^{*r}-\\frac{1}{B}\\sum^N_{r'=1}\\hat{\\alpha}^{*r'})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0    70   \n",
       "1  15.0          8         350.0        165    3693          11.5    70   \n",
       "2  18.0          8         318.0        150    3436          11.0    70   \n",
       "3  16.0          8         304.0        150    3433          12.0    70   \n",
       "4  17.0          8         302.0        140    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 5.3.1 The Validation Set Approach\n",
    "np.random.seed(0)\n",
    "df = pd.read_csv('../data/Auto.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median 구하기\n",
    "temp = df.loc[df['horsepower']!= '?']\n",
    "\n",
    "for i in range(len(df['horsepower'])):\n",
    "    if (df.loc[i,['horsepower']][0] == '?'):\n",
    "        df.loc[i, ['horsepower']] = np.median(temp['horsepower'].astype('float'))\n",
    "df['horsepower'] = df['horsepower'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.266509459607946"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.sample(n=192, random_state=1)\n",
    "test_df = df.loc[~df.index.isin(train_df.index)]\n",
    "\n",
    "model1 = sm.OLS.from_formula('mpg ~ horsepower', data=train_df).fit()\n",
    "pred = model1.predict(test_df)\n",
    "np.average(np.power(test_df['mpg'] - pred,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.86836318037222"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = sm.OLS.from_formula('mpg ~ pow(horsepower,2)', data=train_df).fit()\n",
    "pred = model2.predict(test_df)\n",
    "np.average(pow(test_df['mpg'] - pred,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.72854819158995"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = sm.OLS.from_formula('mpg ~ pow(horsepower,3)', data=train_df).fit()\n",
    "pred = model3.predict(test_df)\n",
    "np.average(pow(test_df['mpg'] - pred,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 5.3.2 Leave-One-Out Cross-Validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "loocv_kf = KFold(n_splits=len(train_df), random_state=1, shuffle=True)\n",
    "loocv_kf.get_n_splits(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split 후 편의성을 위해 문자열 피쳐 삭제\n",
    "\n",
    "train_df_X = train_df[train_df.columns.difference(['mpg'])].drop('name', axis=1)\n",
    "train_df_y = train_df['mpg']\n",
    "test_df_X = test_df[test_df.columns.difference(['mpg'])].drop('name', axis=1)\n",
    "test_df_y = test_df['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.002202001564475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scores = []\n",
    "\n",
    "# kfold 하기 전에 X를 np.array로 바꿔주어야 오류가 나지 않음\n",
    "train_df_X = np.array(train_df_X)\n",
    "train_df_y = np.array(train_df_y)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(loocv_kf.split(train_df_X)):\n",
    "    X_train, X_val = train_df_X[train_idx], train_df_X[val_idx]\n",
    "    y_train, y_val = train_df_y[train_idx], train_df_y[val_idx]\n",
    "\n",
    "    # OLS model\n",
    "    loocv_model = LinearRegression().fit(X_train, y_train) # 각 분할 마다 모델을 다시 선언해주어야 한다.\n",
    "    preds = loocv_model.predict(X_val)\n",
    "    scores.append(mean_squared_error(y_pred = preds, y_true= y_val))\n",
    "\n",
    "# loocv score\n",
    "print(np.average(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regressiondms GLM의 베르누이 분포\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#generalized-linear-models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.699253489446509\n"
     ]
    }
   ],
   "source": [
    "# 5.3.3 k-Fold Cross-Validation\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "kf_score = []\n",
    "strat_kf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "strat_kf_score = []\n",
    "\n",
    "# kFold\n",
    "for (train_idx, val_idx) in kf.split(train_df_X):\n",
    "    X_train, X_val = train_df_X[train_idx], train_df_X[val_idx]\n",
    "    y_train, y_val = train_df_y[train_idx], train_df_y[val_idx]\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    kf_score.append(mean_squared_error(preds, y_val))\n",
    "\n",
    "print(np.average(kf_score))\n",
    "\n",
    "# stratifiedKFold => 결과값의 각 클래스 비율이 동일하게 나오도록 하는 것. target이 연속형이면 의미가 없음\n",
    "for (train_idx, val_idx) in enumerate(strat_kf.split(train_df_X, train_df_y)):\n",
    "    X_train, X_val = train_df_X[train_idx], train_df_X[val_idx]\n",
    "    y_train, y_val = train_df_y[train_idx], train_df_y[val_idx]\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    strat_kf_score.append(mean_squared_error(preds, y_val))\n",
    "\n",
    "print(np.average(strat_kf_score))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.895251</td>\n",
       "      <td>-0.234924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.562454</td>\n",
       "      <td>-0.885176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417090</td>\n",
       "      <td>0.271888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.044356</td>\n",
       "      <td>-0.734198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.315568</td>\n",
       "      <td>0.841983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y\n",
       "0 -0.895251 -0.234924\n",
       "1 -1.562454 -0.885176\n",
       "2 -0.417090  0.271888\n",
       "3  1.044356 -0.734198\n",
       "4 -0.315568  0.841983"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5766511516104116\n"
     ]
    }
   ],
   "source": [
    "# 5.3.4 Bootstrap\n",
    "\n",
    "portfolio = pd.read_csv('../data/Portfolio.csv')\n",
    "\n",
    "def bootstrap_alpha(data, idx:list):\n",
    "    X = data.loc[idx,'X']\n",
    "    Y = data.loc[idx,'Y']\n",
    "     \n",
    "    return (np.var(Y) - np.cov(X, Y)[0,1])/(np.var(X) + np.var(Y) - 2 * np.cov(X,Y)[0,1])\n",
    "\n",
    "range = np.arange(0, 100, 1)\n",
    "print(bootstrap_alpha(portfolio, range))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5426872396960247"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_alpha(portfolio, np.random.uniform(low=0,high=100, size=1000).astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kmlee')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d50b53f7eecc192699096c3b322d2e418f52a0f23d06ad75ff9fc286d66daf3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
